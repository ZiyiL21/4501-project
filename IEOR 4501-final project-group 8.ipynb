{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3dbfd726",
   "metadata": {},
   "source": [
    "# Understanding Hired Rides in NYC\n",
    "\n",
    "_[Project prompt](https://docs.google.com/document/d/1VERPjEZcC1XSs4-02aM-DbkNr_yaJVbFjLJxaYQswqA/edit#)_\n",
    "\n",
    "_This scaffolding notebook may be used to help setup your final project. It's **totally optional** whether you make use of this or not._\n",
    "\n",
    "_If you do use this notebook, everything provided is optional as well - you may remove or add prose and code as you wish._\n",
    "\n",
    "_Anything in italics (prose) or comments (in code) is meant to provide you with guidance. **Remove the italic lines and provided comments** before submitting the project, if you choose to use this scaffolding. We don't need the guidance when grading._\n",
    "\n",
    "_**All code below should be consider \"pseudo-code\" - not functional by itself, and only a suggestion at the approach.**_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "380e10b3",
   "metadata": {},
   "source": [
    "## Requirements\n",
    "\n",
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project._\n",
    "\n",
    "* Code clarity: make sure the code conforms to:\n",
    "    * [ ] [PEP 8](https://peps.python.org/pep-0008/) - You might find [this resource](https://realpython.com/python-pep8/) helpful as well as [this](https://github.com/dnanhkhoa/nb_black) or [this](https://jupyterlab-code-formatter.readthedocs.io/en/latest/) tool\n",
    "    * [ ] [PEP 257](https://peps.python.org/pep-0257/)\n",
    "    * [ ] Break each task down into logical functions\n",
    "* The following files are submitted for the project (see the project's GDoc for more details):\n",
    "    * [ ] `README.md`\n",
    "    * [ ] `requirements.txt`\n",
    "    * [ ] `.gitignore`\n",
    "    * [ ] `schema.sql`\n",
    "    * [X] 6 query files (using the `.sql` extension), appropriately named for the purpose of the query\n",
    "    * [x] Jupyter Notebook containing the project (this file!)\n",
    "* [x] You can edit this cell and add a `x` inside the `[ ]` like this task to denote a completed task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15590f8",
   "metadata": {},
   "source": [
    "## Project Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "767cab44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all import statements needed for the project, for example:\n",
    "\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "\n",
    "import bs4\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import requests\n",
    "import sqlalchemy as db\n",
    "import pyarrow.parquet as pq\n",
    "import re\n",
    "import numpy as np\n",
    "import sys\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "42f48d6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in /Users/lzy/opt/anaconda3/lib/python3.8/site-packages (10.0.1)\n",
      "Requirement already satisfied: numpy>=1.16.6 in /Users/lzy/opt/anaconda3/lib/python3.8/site-packages (from pyarrow) (1.19.5)\n",
      "Requirement already satisfied: geopandas in /Users/lzy/opt/anaconda3/lib/python3.8/site-packages (0.12.1)\n",
      "Requirement already satisfied: packaging in /Users/lzy/opt/anaconda3/lib/python3.8/site-packages (from geopandas) (20.4)\n",
      "Requirement already satisfied: fiona>=1.8 in /Users/lzy/opt/anaconda3/lib/python3.8/site-packages (from geopandas) (1.8.22)\n",
      "Requirement already satisfied: pyproj>=2.6.1.post1 in /Users/lzy/opt/anaconda3/lib/python3.8/site-packages (from geopandas) (3.4.0)\n",
      "Requirement already satisfied: shapely>=1.7 in /Users/lzy/opt/anaconda3/lib/python3.8/site-packages (from geopandas) (1.8.5.post1)\n",
      "Requirement already satisfied: pandas>=1.0.0 in /Users/lzy/opt/anaconda3/lib/python3.8/site-packages (from geopandas) (1.1.5)\n",
      "Requirement already satisfied: six in /Users/lzy/opt/anaconda3/lib/python3.8/site-packages (from packaging->geopandas) (1.15.0)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/lzy/opt/anaconda3/lib/python3.8/site-packages (from packaging->geopandas) (2.4.7)\n",
      "Requirement already satisfied: setuptools in /Users/lzy/opt/anaconda3/lib/python3.8/site-packages (from fiona>=1.8->geopandas) (65.4.1)\n",
      "Requirement already satisfied: munch in /Users/lzy/opt/anaconda3/lib/python3.8/site-packages (from fiona>=1.8->geopandas) (2.5.0)\n",
      "Requirement already satisfied: click>=4.0 in /Users/lzy/opt/anaconda3/lib/python3.8/site-packages (from fiona>=1.8->geopandas) (7.1.2)\n",
      "Requirement already satisfied: cligj>=0.5 in /Users/lzy/opt/anaconda3/lib/python3.8/site-packages (from fiona>=1.8->geopandas) (0.7.2)\n",
      "Requirement already satisfied: certifi in /Users/lzy/opt/anaconda3/lib/python3.8/site-packages (from fiona>=1.8->geopandas) (2020.6.20)\n",
      "Requirement already satisfied: click-plugins>=1.0 in /Users/lzy/opt/anaconda3/lib/python3.8/site-packages (from fiona>=1.8->geopandas) (1.1.1)\n",
      "Requirement already satisfied: attrs>=17 in /Users/lzy/opt/anaconda3/lib/python3.8/site-packages (from fiona>=1.8->geopandas) (19.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in /Users/lzy/opt/anaconda3/lib/python3.8/site-packages (from pandas>=1.0.0->geopandas) (2.8.1)\n",
      "Requirement already satisfied: numpy>=1.15.4 in /Users/lzy/opt/anaconda3/lib/python3.8/site-packages (from pandas>=1.0.0->geopandas) (1.19.5)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/lzy/opt/anaconda3/lib/python3.8/site-packages (from pandas>=1.0.0->geopandas) (2020.1)\n"
     ]
    }
   ],
   "source": [
    "# any general notebook setup, like log formatting\n",
    "!pip install pyarrow\n",
    "!pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c51c2b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#urls\n",
    "TAXI_URL = \"https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n",
    "\n",
    "#local csvs\n",
    "UBER_DATA = \"uber_rides_sample.csv\"\n",
    "WEATHER_CSV = [\"2015_weather.csv\",\"2014_weather.csv\",\"2013_weather.csv\",\"2012_weather.csv\",\"2011_weather.csv\",\"2010_weather.csv\",\"2009_weather.csv\"]\n",
    "\n",
    "#coords\n",
    "NEW_YORK_BOX_COORDS = ((40.560445, -74.242330), (40.908524, -73.717047))\n",
    "\n",
    "DATABASE_URL = \"sqlite:///project.db\"\n",
    "DATABASE_SCHEMA_FILE = \"schema.sql\"\n",
    "QUERY_DIRECTORY = \"queries\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995f975e",
   "metadata": {},
   "source": [
    "## Part 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21befe52",
   "metadata": {},
   "source": [
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project. The order of these tasks aren't necessarily the order in which they need to be done. It's okay to do them in an order that makes sense to you._\n",
    "\n",
    "* [ ] Define a function that calculates the distance between two coordinates in kilometers that **only uses the `math` module** from the standard library.\n",
    "* [ ] Taxi data:\n",
    "    * [ ] Use the `re` module, and the packages `requests`, BeautifulSoup (`bs4`), and (optionally) `pandas` to programmatically download the required CSV files & load into memory.\n",
    "    * You may need to do this one file at a time - download, clean, sample. You can cache the sampling by saving it as a CSV file (and thereby freeing up memory on your computer) before moving onto the next file. \n",
    "* [ ] Weather & Uber data:\n",
    "    * [ ] Download the data manually in the link provided in the project doc.\n",
    "* [ ] All data:\n",
    "    * [ ] Load the data using `pandas`\n",
    "    * [ ] Clean the data, including:\n",
    "        * Remove unnecessary columns\n",
    "        * Remove invalid data points (take a moment to consider what's invalid)\n",
    "        * Normalize column names\n",
    "        * (Taxi & Uber data) Remove trips that start and/or end outside the designated [coordinate box](http://bboxfinder.com/#40.560445,-74.242330,40.908524,-73.717047)\n",
    "    * [ ] (Taxi data) Sample the data so that you have roughly the same amount of data points over the given date range for both Taxi data and Uber data.\n",
    "* [ ] Weather data:\n",
    "    * [ ] Split into two `pandas` DataFrames: one for required hourly data, and one for the required daily daya.\n",
    "    * [ ] You may find that the weather data you need later on does not exist at the frequency needed (daily vs hourly). You may calculate/generate samples from one to populate the other. Just document what you’re doing so we can follow along. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c7fb91",
   "metadata": {},
   "source": [
    "### Calculating distance\n",
    "_**TODO:** To find the trip distance by transfering coordinates (degrees) into the distance in kilometers._\n",
    "\n",
    "_**step1:** get the latitude and longitude from the coordinates and transfer from degrees to radians._\n",
    "\n",
    "_**step2:** get the distance of two latitudes and longitudes from step1._\n",
    "\n",
    "_**step3:** import the results from step2 into the formal equation of calculating distance._\n",
    "\n",
    "_**step4:** import a new column \"distance\" into the dataframe with the result of step3._\n",
    "\n",
    "_NOTE: suppose the radius of earth in kilometers is 6378._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "856216a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_distance(from_coord, to_coord):\n",
    "    \n",
    "    #step1:get the latitude and longitude from the coordinates and transfer from degrees to radians.\n",
    "    pick_lat = from_coord[\"pickup_latitude\"].map(radians)\n",
    "    pick_long = from_coord[\"pickup_longitude\"].map(radians)\n",
    "    drop_lat = to_coord[\"dropoff_latitude\"].map(radians)\n",
    "    drop_long = to_coord[\"dropoff_longitude\"].map(radians)\n",
    "    \n",
    "    #step2: get the distance of two latitudes and longitudes from step1.\n",
    "    distance_long = pick_long - drop_long\n",
    "    distance_lat = pick_lat - drop_lat\n",
    "    \n",
    "    #step3: import the results from step2 into the formal equation of calculating distance.\n",
    "    x = ((distance_lat / 2).map(sin))**2 + (pick_lat).map(cos) * (drop_lat).map(cos) * ((distance_long / 2).map(sin))**2\n",
    "    c = 2 * (x.map(sqrt)).map(asin)\n",
    "    r = 6378 # Radius of earth in kilometers\n",
    "    \n",
    "    return c*r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6ba3fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_distance_column(dataframe):\n",
    "    #step4: import a new column \"distance\" into the dataframe with the result of step3.\n",
    "    from_coord = dataframe[[\"pickup_latitude\",\"pickup_longitude\"]]\n",
    "    to_coord = dataframe[[\"dropoff_latitude\",\"dropoff_longitude\"]]\n",
    "    \n",
    "    dataframe[\"distance\"] = calculate_distance(from_coord, to_coord)\n",
    "    dataframe[\"distance\"] = dataframe[\"distance\"].astype(\"float32\")\n",
    "    \n",
    "    # remove distance = 0\n",
    "    dataframe = dataframe[dataframe['distance']>0.000001]\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25dd1672",
   "metadata": {},
   "source": [
    "### Processing Taxi Data\n",
    "\n",
    "_**TODO:** Downloand, Clean, and Sample Yellow Taxi Trip Records._\n",
    "\n",
    "_**step1:** get source data from the website: 78 \"Yellow Taxi Trip Records\" parquet files (from 2009.01 to 2015.06)._\n",
    "\n",
    "_**step2:** upzip taxi_zones file._\n",
    "\n",
    "_**step3:** Clean data: normalize column names, remove unneccessary columns and data points by requirements, standardize the data type._\n",
    "            \n",
    "_**step4:** Sample data: according to the 200,000 samples in uber data, each month we select 2564 samples from the taxi data._\n",
    "\n",
    "_**step5:** Create a gigantic dataframe combining cleaned data in every month._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfd9b173",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_taxi_parquet_links():\n",
    "    \n",
    "    response = requests.get(TAXI_URL)\n",
    "    html = response.content\n",
    "    soup = bs4.BeautifulSoup(html, \"html.parser\") # Use BeautifulSoup to \"pretty\"-print the HTML we downloaded\n",
    "    yellow_a_tags = soup.find_all(\"a\", attrs={\"title\": \"Yellow Taxi Trip Records\"})\n",
    "    result = [a[\"href\"] for a in yellow_a_tags]\n",
    "    # Only get the links for yellow taxi data between 2009-01 and 2015-06\n",
    "    pattern = re.compile(\n",
    "    r\"yellow_tripdata_20((15-0([1-6]))|(09-(\\d{2}))|(1[0-4]-(\\d{2}))).parquet\"\n",
    "    )\n",
    "    links = []\n",
    "    for link in result:\n",
    "        match = pattern.search(link)\n",
    "        if match:\n",
    "            links.append(match.string) \n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64e0cd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_month_taxi_data(url):\n",
    "\n",
    "    df = pd.read_parquet(url) \n",
    "\n",
    "    taxi_zones = gpd.read_file(filename='taxi_zones.zip', engine='fiona')\n",
    "    taxi_zones = taxi_zones.to_crs(4326)\n",
    "    # Extract x, y in the coordinates as longitude and latitude\n",
    "    taxi_zones['longitude'] = taxi_zones.centroid.x \n",
    "    taxi_zones['latitude'] = taxi_zones.centroid.y\n",
    "\n",
    "    # Convert PULocationID and DOLocationID to pickup_latitude, pickup_longitude, dropoff_latitude, and dropoff_longitude\n",
    "    if 'PULocationID' in df.columns:\n",
    "        df['pickup_latitude'] = df['PULocationID'].map(taxi_zones['latitude'])\n",
    "        df['pickup_longitude'] = df['PULocationID'].map(taxi_zones['longitude'])\n",
    "    if 'DOLocationID' in df.columns:\n",
    "        df['dropoff_latitude'] = df['DOLocationID'].map(taxi_zones['latitude'])\n",
    "        df['dropoff_longitude'] = df['DOLocationID'].map(taxi_zones['longitude'])\n",
    "        \n",
    "    # Set all column names to lower case    \n",
    "    df = df.rename(columns=str.lower)\n",
    "    \n",
    "    # Normalize column names\n",
    "    df.rename(columns={'tpep_pickup_datetime':'pickup_datetime','trip_pickup_datetime':'pickup_datetime',\n",
    "                       'tpep_dropoff_datetime':'dropoff_datetime','trip_dropoff_datetime':'dropoff_datetime',\n",
    "                       'start_lon':'pickup_longitude', 'start_lat':'pickup_latitude', \n",
    "                       'end_lon':'dropoff_longitude', 'end_lat':'dropoff_latitude','tip_amt':'tip_amount'}, inplace=True)\n",
    "    \n",
    "    # Remove invalid data points\n",
    "    df.dropna(subset=['pickup_latitude','pickup_longitude','dropoff_latitude','dropoff_longitude','tip_amount'],inplace=True)\n",
    "    df = df[df['passenger_count'] >= 1]\n",
    "    \n",
    "    # Remove unnecessary columns\n",
    "    df = df[['pickup_datetime','pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude','tip_amount']]\n",
    "\n",
    "    # Remove trips that start and/or end outside the designated coordinate box (NEW_YORK_BOX_COORDS)\n",
    "    df = df[(df['pickup_latitude'] >= NEW_YORK_BOX_COORDS[0][0]) & (df['pickup_latitude'] <= NEW_YORK_BOX_COORDS[1][0])\n",
    "            & (df['pickup_longitude'] >= NEW_YORK_BOX_COORDS[0][1]) & (df['pickup_longitude'] <= NEW_YORK_BOX_COORDS[1][1])]\n",
    "    df = df[(df['dropoff_latitude'] >= NEW_YORK_BOX_COORDS[0][0]) & (df['dropoff_latitude'] <= NEW_YORK_BOX_COORDS[1][0])\n",
    "            & (df['dropoff_longitude'] >= NEW_YORK_BOX_COORDS[0][1]) & (df['dropoff_longitude'] <= NEW_YORK_BOX_COORDS[1][1])]\n",
    "\n",
    "\n",
    "    # Sample\n",
    "    df = df.sample(n=2564)\n",
    "    \n",
    "    # Use appropriate type for each column\n",
    "    df = df.reset_index(drop=True)\n",
    "    df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])\n",
    "    df.iloc[:,1:7] = df.iloc[:,1:7].astype(\"float32\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48c9dd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_and_clean_taxi_data():\n",
    "    all_taxi_dataframes = []\n",
    "    \n",
    "    all_parquet_urls = find_taxi_parquet_links()\n",
    "    for parquet_url in tqdm(all_parquet_urls):\n",
    "        dataframe = get_and_clean_month_taxi_data(parquet_url)\n",
    "        add_distance_column(dataframe)\n",
    "        \n",
    "        all_taxi_dataframes.append(dataframe)\n",
    "        \n",
    "    # create one gigantic dataframe with data from every month needed\n",
    "    taxi_data = pd.concat(all_taxi_dataframes)\n",
    "        \n",
    "    return taxi_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a18695b",
   "metadata": {},
   "source": [
    "### Processing Uber Data\n",
    "\n",
    "_**TODO:** Get cleaned Uber Rides Sample records._\n",
    "\n",
    "_**step1:** Remove unneccessary columns and data points by requirements, standardize the data type._\n",
    "            \n",
    "_**step2:** Create a dataframe with cleaned datapoints._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "232f224a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_uber_data(csv_file):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Remove unnecessary columns\n",
    "    df = df[['pickup_datetime','pickup_longitude','pickup_latitude','dropoff_longitude','dropoff_latitude']]\n",
    "    \n",
    "    # Remove trips that start and/or end outside the designated coordinate box (NEW_YORK_BOX_COORDS)\n",
    "    df = df[(df['pickup_latitude'] >= NEW_YORK_BOX_COORDS[0][0]) & (df['pickup_latitude'] <= NEW_YORK_BOX_COORDS[1][0])\n",
    "            & (df['pickup_longitude'] >= NEW_YORK_BOX_COORDS[0][1]) & (df['pickup_longitude'] <= NEW_YORK_BOX_COORDS[1][1])]\n",
    "    \n",
    "    # Use appropriate type for each column\n",
    "    df['pickup_datetime'] = pd.to_datetime(df['pickup_datetime'])\n",
    "    df.iloc[:,1:5] = df.iloc[:,1:5].astype(\"float32\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbcd0a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_uber_data():\n",
    "    uber_dataframe = load_and_clean_uber_data(UBER_DATA)\n",
    "    add_distance_column(uber_dataframe)\n",
    "    return uber_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1595b3",
   "metadata": {},
   "source": [
    "### Processing Weather Data\n",
    "\n",
    "_**TODO:** Get claned Weather data records by creating two dataFrames: one for required hourly data, and one for the required daily data._\n",
    "\n",
    "_**step1:** Normalize the columns, remove unneccessary columns and data points by requirements, standardize the data type, and fillout the required blanks._\n",
    "            \n",
    "_**step2:** Create two required dataframes with cleaned datapoints._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "481cb1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_hourly(csv_file):\n",
    "    \n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    # Get the required columns\n",
    "    df = df[[\"DATE\",\"HourlyPrecipitation\", \"HourlyWindSpeed\"]]\n",
    "    \n",
    "    # Normalize the 'Precipitation' columns into numeric form (dtype: float32) and fillout the blank with value 0\n",
    "    df[\"HourlyPrecipitation\"].fillna(value = 0, inplace = True) # assume HourlyPrecipitation is 0 if the value is NaN\n",
    "    df[df[\"HourlyPrecipitation\"]==\"T\"] = float(0.00001) # T is trivial, so use 0.00001 to replace T\n",
    "    df[df[\"HourlyPrecipitation\"]==\"M\"] = np.nan # M represents missing value, so leave NaN here\n",
    "    df['HourlyPrecipitation'] = pd.to_numeric(df['HourlyPrecipitation'], errors = \"coerce\") \n",
    "    \n",
    "    # Fill out the missing blank for 'WindSpeed' with 0\n",
    "    df[\"HourlyWindSpeed\"].fillna(value = 0, inplace = True) # assume WindSpeed is 0 if the value is NaN\n",
    "    \n",
    "    # Normalize the 'DATE' columns into datetime form\n",
    "    df[\"DATE\"] = pd.to_datetime(df[\"DATE\"])\n",
    "    df = df.astype({\"HourlyWindSpeed\":\"int8\",\"HourlyPrecipitation\":\"float32\"})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "bc4d435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_month_weather_data_daily(csv_file):\n",
    "    df = clean_month_weather_data_hourly(csv_file)\n",
    "    df['DATE'] = pd.to_datetime(df['DATE'], errors='coerce').dt.date # convert DATE to YYYY-MM-DD form\n",
    "    df_windspeed = df.groupby('DATE')['HourlyWindSpeed'].mean() # calculate daily average windspeed\n",
    "    df_precipitation = df.groupby('DATE')['HourlyPrecipitation'].sum() # calculate daily precipitation\n",
    "    \n",
    "    df = pd.merge(df_windspeed,df_precipitation,on='DATE') # merge two dataframe\n",
    "    df.reset_index(inplace=True)\n",
    "    df = df.rename(columns={'HourlyWindSpeed': 'DailyWindSpeed', 'HourlyPrecipitation': 'DailyPrecipitation'})\n",
    "    df = df.astype({\"DailyWindSpeed\":\"int8\",\"DailyPrecipitation\":\"float32\"})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9647d2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_clean_weather_data():\n",
    "    hourly_dataframes = []\n",
    "    daily_dataframes = []\n",
    "    \n",
    "    # add the name manually\n",
    "    weather_csv_files = [\"2015_weather.csv\",\"2014_weather.csv\",\"2013_weather.csv\",\"2012_weather.csv\",\"2011_weather.csv\",\"2010_weather.csv\",\"2009_weather.csv\"]\n",
    "    \n",
    "    for csv_file in tqdm(weather_csv_files):\n",
    "        hourly_dataframe = clean_month_weather_data_hourly(csv_file)\n",
    "        daily_dataframe = clean_month_weather_data_daily(csv_file)\n",
    "        hourly_dataframes.append(hourly_dataframe)\n",
    "        daily_dataframes.append(daily_dataframe)\n",
    "        \n",
    "    # create two dataframes with hourly & daily data from every month\n",
    "    hourly_data = pd.concat(hourly_dataframes)\n",
    "    daily_data = pd.concat(daily_dataframes)\n",
    "    \n",
    "    return hourly_data, daily_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4d6c99c",
   "metadata": {},
   "source": [
    "### Process All Data\n",
    "\n",
    "_This is where you can actually execute all the required functions._\n",
    "\n",
    "_**TODO:** Write some prose that tells the reader what you're about to do here._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9ae5d5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [52:12<00:00, 40.17s/it]\n"
     ]
    }
   ],
   "source": [
    "taxi_data = get_and_clean_taxi_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b4e36b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_data = get_uber_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "95aeb8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7/7 [00:01<00:00,  4.66it/s]\n"
     ]
    }
   ],
   "source": [
    "hourly_weather_data, daily_weather_data = load_and_clean_weather_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e974b897",
   "metadata": {},
   "source": [
    "## Part 2: Storing Cleaned Data\n",
    "\n",
    "_**TODO:** Store the cleaned data into the SCHEMA.SQL file by creating tables for each data set using SQL._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d766fe27",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = db.create_engine(DATABASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "7e41ee6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sqlalchemy.engine.result.ResultProxy at 0x7ff45d7ccf70>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.execute(\"DROP TABLE uber_trips\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f2a7f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create required tables\n",
    "HOURLY_WEATHER_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS hourly_weather\n",
    "(\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    DATE DATE,\n",
    "    HourlyWindSpeed INTETER,\n",
    "    HourlyPrecipitation FLOAT\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "DAILY_WEATHER_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS daily_weather\n",
    "(\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    DATE DATE,\n",
    "    DailyWindSpeed INTETER,\n",
    "    DailyPrecipitation FLOAT\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "TAXI_TRIPS_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS taxi_trips\n",
    "(\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    pickup_datetime DATE,\n",
    "    pickup_longitude FLOAT,\n",
    "    pickup_latitude FLOAT,\n",
    "    dropoff_longitude FLOAT,\n",
    "    dropoff_latitude FLOAT,\n",
    "    tip_amount FLOAT,\n",
    "    distance FLOAT\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "UBER_TRIPS_SCHEMA = \"\"\"\n",
    "CREATE TABLE IF NOT EXISTS uber_trips\n",
    "(\n",
    "    id INTEGER PRIMARY KEY,\n",
    "    pickup_datetime DATE,\n",
    "    pickup_longitude FLOAT,\n",
    "    pickup_latitude FLOAT,\n",
    "    dropoff_longitude FLOAT,\n",
    "    dropoff_latitude FLOAT,\n",
    "    distance FLOAT\n",
    ")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "62303e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create that required schema.sql file\n",
    "with open(DATABASE_SCHEMA_FILE, \"w\") as f:\n",
    "    f.write(HOURLY_WEATHER_SCHEMA)\n",
    "    f.write(DAILY_WEATHER_SCHEMA)\n",
    "    f.write(TAXI_TRIPS_SCHEMA)\n",
    "    f.write(UBER_TRIPS_SCHEMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "e2de7981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the tables with the schema files\n",
    "with engine.connect() as connection:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2336cdca",
   "metadata": {},
   "source": [
    "### Add Data to Database\n",
    "\n",
    "_**TODO:** Add dataframes to corresponding tables._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "a9bc8160",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dataframes_to_table(table_to_df_dict):\n",
    "    for table, df in table_to_df_dict.items():\n",
    "        df.to_sql(table, con=engine, if_exists=\"append\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "08b0d4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_table_name_to_dataframe = {\n",
    "    \"taxi_trips\": taxi_data,\n",
    "    \"uber_trips\": uber_data,\n",
    "    \"hourly_weather\": hourly_weather_data,\n",
    "    \"daily_weather\": daily_weather_data,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "2f3a0d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dataframes_to_table(map_table_name_to_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15325d12",
   "metadata": {},
   "source": [
    "## Part 3: Understanding the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc67f47f",
   "metadata": {},
   "source": [
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project. The order of these tasks aren't necessarily the order in which they need to be done. It's okay to do them in an order that makes sense to you._\n",
    "\n",
    "* [ ] For 01-2009 through 06-2015, what hour of the day was the most popular to take a yellow taxi? The result should have 24 bins.\n",
    "* [ ] For the same time frame, what day of the week was the most popular to take an uber? The result should have 7 bins.\n",
    "* [ ] What is the 95% percentile of distance traveled for all hired trips during July 2013?\n",
    "* [ ] What were the top 10 days with the highest number of hired rides for 2009, and what was the average distance for each day?\n",
    "* [ ] Which 10 days in 2014 were the windiest, and how many hired trips were made on those days?\n",
    "* [ ] During Hurricane Sandy in NYC (Oct 29-30, 2012) and the week leading up to it, how many trips were taken each hour, and for each hour, how much precipitation did NYC receive and what was the sustained wind speed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c587403",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function that help write answer of the query to the schema file\n",
    "def write_query_to_file(query, outfile):\n",
    "    with open(QUERY_DIRECTORY + \"/\" + outfile, \"w\") as f:\n",
    "        f.write(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633aed0d",
   "metadata": {},
   "source": [
    "### Query #1\n",
    "\n",
    "_**TODO:** Find the most popular hour of the day to take a yellow taxi from 01-2009 to 06-2015._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "fdee8fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_1 = \"\"\"\n",
    "SELECT strftime(\"%H\", pickup_datetime) AS hours,\n",
    "COUNT(*) AS hour_frequency\n",
    "FROM taxi_trips\n",
    "GROUP BY hours\n",
    "ORDER BY hour_frequency desc\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "2d1deee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('19', 12590),\n",
       " ('18', 12094),\n",
       " ('20', 12006),\n",
       " ('21', 11665),\n",
       " ('22', 11181),\n",
       " ('14', 10095),\n",
       " ('23', 9955),\n",
       " ('17', 9897),\n",
       " ('12', 9819),\n",
       " ('13', 9632),\n",
       " ('15', 9526),\n",
       " ('09', 9185),\n",
       " ('11', 9156),\n",
       " ('08', 9027),\n",
       " ('10', 8946),\n",
       " ('16', 8103),\n",
       " ('00', 7889),\n",
       " ('07', 7367),\n",
       " ('01', 5921),\n",
       " ('02', 4345),\n",
       " ('06', 4050),\n",
       " ('03', 3277),\n",
       " ('04', 2318),\n",
       " ('05', 1948)]"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.execute(QUERY_1).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "6a01e32a",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_1, \"popular_hours_of_taxi.sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcc6c3c",
   "metadata": {},
   "source": [
    "### Query #2\n",
    "\n",
    "_**TODO:** Find the most popular day of the week to take an uber from 01-2009 to 06-2015._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "bd1d210f",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_2 = \"\"\"\n",
    "SELECT strftime(\"%w\", pickup_datetime) AS days,\n",
    "COUNT(*) AS day_frequency\n",
    "FROM uber_trips\n",
    "GROUP BY days\n",
    "ORDER BY day_frequency DESC;\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "ed489e7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('5', 30223),\n",
       " ('6', 29643),\n",
       " ('4', 29389),\n",
       " ('3', 28381),\n",
       " ('2', 27579),\n",
       " ('0', 25877),\n",
       " ('1', 24733)]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.execute(QUERY_2).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "9bd2e52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_2, \"popular_days_of_uber.sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87474be1",
   "metadata": {},
   "source": [
    "### Query #3\n",
    "\n",
    "_**TODO:** Find the 95% percentile of distance traveled for all hired trips during July 2013._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "5352835a",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_3 = \"\"\"\n",
    "WITH hired_trips AS\n",
    "(\n",
    "    SELECT pickup_datetime, distance FROM taxi_trips\n",
    "    WHERE pickup_datetime BETWEEN \"2013-07-01 00:00:00\" AND \"2013-07-31 23:59:59\"\n",
    "    UNION ALL\n",
    "    SELECT pickup_datetime, distance FROM uber_trips\n",
    "    WHERE pickup_datetime BETWEEN \"2013-07-01 00:00:00\" AND \"2013-07-31 23:59:59\"\n",
    ")\n",
    "\n",
    "SELECT distance\n",
    "FROM hired_trips\n",
    "ORDER BY distance desc\n",
    "\n",
    "LIMIT 1\n",
    "OFFSET (SELECT COUNT(*) FROM hired_trips) * 5/100 \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "617f54b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(22.87126922607422,)]"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.execute(QUERY_3).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "1cc52abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_3, \"95_percentile_of_hired_trips.sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e19ae745",
   "metadata": {},
   "source": [
    "### Query #4\n",
    "\n",
    "_**TODO 1:** Find the top 10 days with the highest number of hired rides for 2009._\n",
    "\n",
    "_**TODO 2:** Find the average distance for each day._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "id": "e2d2bc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_4 = \"\"\"\n",
    "WITH hired_trips AS\n",
    "(\n",
    "    SELECT pickup_datetime, distance FROM taxi_trips\n",
    "    WHERE pickup_datetime BETWEEN \"2009-01-01 00:00:00\" AND \"2009-12-31 23:59:59\"\n",
    "    UNION ALL\n",
    "    SELECT pickup_datetime, distance FROM uber_trips\n",
    "    WHERE pickup_datetime BETWEEN \"2009-01-01 00:00:00\" AND \"2009-12-31 23:59:59\"\n",
    ")\n",
    "\n",
    "SELECT DATE(pickup_datetime) AS dates,\n",
    "AVG(distance) AS average_distance,\n",
    "COUNT(*) AS number_of_hired_rides\n",
    "\n",
    "FROM hired_trips\n",
    "\n",
    "GROUP BY dates\n",
    "ORDER BY number_of_hired_rides desc\n",
    "\n",
    "LIMIT 10\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "2e892a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2009-05-08', 3.1836303715647447, 227),\n",
       " ('2009-12-11', 3.366657016345778, 222),\n",
       " ('2009-01-31', 3.2121477948355786, 217),\n",
       " ('2009-12-16', 3.1220933549881216, 212),\n",
       " ('2009-12-05', 3.1096567303164018, 210),\n",
       " ('2009-04-23', 2.7710478264981737, 208),\n",
       " ('2009-12-18', 2.9544812311604787, 207),\n",
       " ('2009-07-23', 3.327083624287504, 207),\n",
       " ('2009-03-12', 3.0113140594232197, 207),\n",
       " ('2009-02-14', 3.3200396210408503, 207)]"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.execute(QUERY_4).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "f175fb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_4, \"top_ten_days_of_hired_trips.sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6bb81e6",
   "metadata": {},
   "source": [
    "### Query #5\n",
    "\n",
    "_**TODO 1:** Find the windiest 10 days in 2014._\n",
    "\n",
    "_**TODO 2:** Find the number of hired trips on those windiest 10 days._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "ee5c6599",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_5 = \"\"\"\n",
    "WITH hired_trips AS\n",
    "(\n",
    "    SELECT pickup_datetime AS date\n",
    "    FROM taxi_trips\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT pickup_datetime AS date\n",
    "    FROM uber_trips\n",
    ")\n",
    "\n",
    "SELECT DATE(date), COUNT(*) AS number_of_hired_trips\n",
    "FROM hired_trips\n",
    "GROUP BY DATE(date)\n",
    "HAVING DATE(date) IN (\n",
    "SELECT DATE FROM daily_weather \n",
    "WHERE DATE BETWEEN \"2014-01-01\" AND \"2014-12-31\"\n",
    "ORDER BY DailyWindSpeed desc \n",
    "LIMIT 10\n",
    ")\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "id": "2ce80f59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2014-01-02', 141),\n",
       " ('2014-01-03', 92),\n",
       " ('2014-01-07', 157),\n",
       " ('2014-02-13', 131),\n",
       " ('2014-03-13', 186),\n",
       " ('2014-03-26', 167),\n",
       " ('2014-03-29', 194),\n",
       " ('2014-12-07', 166),\n",
       " ('2014-12-08', 174),\n",
       " ('2014-12-09', 134)]"
      ]
     },
     "execution_count": 415,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.execute(QUERY_5).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "1da1e767",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_5, \"10_windiest_days.sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abb3bbd",
   "metadata": {},
   "source": [
    "### Query #6\n",
    "\n",
    "_**TODO 1:** Find the number of trips taken each hour from Oct 29, 2012 to Oct 30, 2012, and the week leading up to it,._\n",
    "\n",
    "_**TODO 2:** Find the amount of precipitation and the sustained wind speed for each hour from above days._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "id": "86873f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_6 = \"\"\"\n",
    "WITH hired_trips AS\n",
    "(\n",
    "    SELECT strftime('%Y-%m-%d %H', pickup_datetime) AS date\n",
    "    FROM taxi_trips\n",
    "    WHERE pickup_datetime BETWEEN \"2012-10-22 00:00:00\" AND \"2012-11-06 23:59:59\"\n",
    "    \n",
    "    UNION ALL\n",
    "    \n",
    "    SELECT strftime('%Y-%m-%d %H', pickup_datetime) AS date\n",
    "    FROM uber_trips\n",
    "    WHERE pickup_datetime BETWEEN \"2012-10-22 00:00:00\" AND \"2012-11-06 23:59:59\"\n",
    ")\n",
    "\n",
    "SELECT strftime('%Y-%m-%d %H', hw.date) AS hour, count(ht.date) AS number_of_hired_trips, hw.HourlyWindSpeed, hw.HourlyPrecipitation\n",
    "FROM hourly_weather hw LEFT JOIN hired_trips ht\n",
    "ON hour = ht.date\n",
    "WHERE hw.date BETWEEN \"2012-10-22 00:00:00\" AND \"2012-11-06 23:59:59\"\n",
    "GROUP BY hour\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "dcb1871e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('2012-10-22 00', 4, 7, 0.0),\n",
       " ('2012-10-22 01', 0, 5, 0.0),\n",
       " ('2012-10-22 02', 3, 7, 0.0),\n",
       " ('2012-10-22 03', 2, 0, 0.0),\n",
       " ('2012-10-22 04', 0, 0, 0.0),\n",
       " ('2012-10-22 05', 2, 0, 0.0),\n",
       " ('2012-10-22 06', 5, 5, 0.0),\n",
       " ('2012-10-22 07', 12, 3, 0.0),\n",
       " ('2012-10-22 08', 6, 3, 0.0),\n",
       " ('2012-10-22 09', 9, 5, 0.0),\n",
       " ('2012-10-22 10', 6, 0, 0.0),\n",
       " ('2012-10-22 11', 11, 0, 0.0),\n",
       " ('2012-10-22 12', 7, 11, 0.0),\n",
       " ('2012-10-22 13', 11, 0, 0.0),\n",
       " ('2012-10-22 14', 5, 7, 0.0),\n",
       " ('2012-10-22 15', 6, 6, 0.0),\n",
       " ('2012-10-22 16', 10, 3, 0.0),\n",
       " ('2012-10-22 17', 5, 7, 0.0),\n",
       " ('2012-10-22 18', 12, 5, 0.0),\n",
       " ('2012-10-22 19', 9, 5, 0.0),\n",
       " ('2012-10-22 20', 11, 3, 0.0),\n",
       " ('2012-10-22 21', 7, 0, 0.0),\n",
       " ('2012-10-22 22', 11, 3, 0.0),\n",
       " ('2012-10-22 23', 8, 3, 0.0),\n",
       " ('2012-10-23 00', 5, 3, 0.0),\n",
       " ('2012-10-23 01', 2, 0, 0.0),\n",
       " ('2012-10-23 02', 1, 3, 0.0),\n",
       " ('2012-10-23 03', 1, 0, 0.0),\n",
       " ('2012-10-23 04', 1, 3, 0.0),\n",
       " ('2012-10-23 05', 3, 0, 0.0),\n",
       " ('2012-10-23 06', 7, 0, 0.0),\n",
       " ('2012-10-23 07', 11, 0, 0.0),\n",
       " ('2012-10-23 08', 13, 0, 0.0),\n",
       " ('2012-10-23 09', 8, 3, 0.0),\n",
       " ('2012-10-23 10', 10, 0, 0.0),\n",
       " ('2012-10-23 11', 9, 3, 0.0),\n",
       " ('2012-10-23 13', 10, 0, 0.0),\n",
       " ('2012-10-23 14', 9, 0, 0.0),\n",
       " ('2012-10-23 15', 10, 0, 0.0),\n",
       " ('2012-10-23 16', 7, 3, 0.0),\n",
       " ('2012-10-23 18', 8, 5, 0.0),\n",
       " ('2012-10-23 20', 16, 0, 0.019999999552965164),\n",
       " ('2012-10-23 22', 8, 0, 0.009999999776482582),\n",
       " ('2012-10-23 23', 6, 0, 0.0),\n",
       " ('2012-10-24 00', 3, 3, 0.0),\n",
       " ('2012-10-24 01', 4, 6, 0.0),\n",
       " ('2012-10-24 02', 20, 5, 0.0),\n",
       " ('2012-10-24 03', 0, 7, 0.0),\n",
       " ('2012-10-24 04', 0, 7, 0.0),\n",
       " ('2012-10-24 05', 4, 6, 0.0),\n",
       " ('2012-10-24 06', 6, 5, 0.0),\n",
       " ('2012-10-24 07', 6, 5, 0.0),\n",
       " ('2012-10-24 09', 7, 0, 0.0),\n",
       " ('2012-10-24 10', 7, 7, 0.0),\n",
       " ('2012-10-24 11', 6, 7, 0.0),\n",
       " ('2012-10-24 12', 6, 8, 0.0),\n",
       " ('2012-10-24 13', 5, 8, 0.0),\n",
       " ('2012-10-24 14', 22, 6, 0.0),\n",
       " ('2012-10-24 15', 9, 7, 0.0),\n",
       " ('2012-10-24 16', 8, 8, 0.0),\n",
       " ('2012-10-24 17', 7, 5, 0.0),\n",
       " ('2012-10-24 18', 11, 7, 0.0),\n",
       " ('2012-10-24 19', 11, 8, 0.0),\n",
       " ('2012-10-24 20', 32, 0, 0.0),\n",
       " ('2012-10-24 21', 26, 3, 0.0),\n",
       " ('2012-10-24 22', 24, 5, 0.0),\n",
       " ('2012-10-24 23', 10, 0, 0.0),\n",
       " ('2012-10-25 00', 14, 6, 0.0),\n",
       " ('2012-10-25 01', 3, 3, 0.0),\n",
       " ('2012-10-25 02', 8, 3, 0.0),\n",
       " ('2012-10-25 03', 0, 6, 0.0),\n",
       " ('2012-10-25 04', 2, 6, 0.0),\n",
       " ('2012-10-25 05', 2, 0, 0.0),\n",
       " ('2012-10-25 06', 5, 5, 0.0),\n",
       " ('2012-10-25 07', 12, 6, 0.0),\n",
       " ('2012-10-25 08', 10, 5, 0.0),\n",
       " ('2012-10-25 09', 7, 3, 0.0),\n",
       " ('2012-10-25 10', 5, 6, 0.0),\n",
       " ('2012-10-25 11', 9, 0, 0.0),\n",
       " ('2012-10-25 12', 11, 6, 0.0),\n",
       " ('2012-10-25 13', 6, 0, 0.0),\n",
       " ('2012-10-25 14', 9, 5, 0.0),\n",
       " ('2012-10-25 15', 10, 5, 0.0),\n",
       " ('2012-10-25 16', 3, 0, 0.0),\n",
       " ('2012-10-25 17', 12, 3, 0.0),\n",
       " ('2012-10-25 18', 8, 0, 0.0),\n",
       " ('2012-10-25 19', 4, 0, 0.0),\n",
       " ('2012-10-25 20', 16, 3, 0.0),\n",
       " ('2012-10-25 21', 14, 3, 0.0),\n",
       " ('2012-10-25 22', 17, 3, 0.0),\n",
       " ('2012-10-25 23', 16, 0, 0.0),\n",
       " ('2012-10-26 00', 24, 0, 0.0),\n",
       " ('2012-10-26 01', 3, 0, 0.0),\n",
       " ('2012-10-26 02', 5, 0, 0.0),\n",
       " ('2012-10-26 03', 2, 3, 0.0),\n",
       " ('2012-10-26 04', 2, 0, 0.0),\n",
       " ('2012-10-26 05', 1, 0, 0.0),\n",
       " ('2012-10-26 06', 1, 0, 0.0),\n",
       " ('2012-10-26 07', 7, 3, 0.0),\n",
       " ('2012-10-26 08', 5, 3, 0.0),\n",
       " ('2012-10-26 09', 7, 3, 0.0),\n",
       " ('2012-10-26 10', 4, 3, 0.0),\n",
       " ('2012-10-26 11', 9, 3, 0.0),\n",
       " ('2012-10-26 12', 5, 0, 0.0),\n",
       " ('2012-10-26 13', 8, 3, 0.0),\n",
       " ('2012-10-26 14', 8, 3, 0.0),\n",
       " ('2012-10-26 15', 7, 0, 0.0),\n",
       " ('2012-10-26 16', 4, 0, 0.0),\n",
       " ('2012-10-26 17', 10, 0, 0.0),\n",
       " ('2012-10-26 18', 8, 0, 0.0),\n",
       " ('2012-10-26 19', 7, 0, 0.0),\n",
       " ('2012-10-26 20', 25, 3, 0.0),\n",
       " ('2012-10-26 21', 10, 3, 0.0),\n",
       " ('2012-10-26 22', 13, 0, 0.0),\n",
       " ('2012-10-26 23', 20, 0, 0.0),\n",
       " ('2012-10-27 00', 10, 3, 0.0),\n",
       " ('2012-10-27 01', 8, 0, 0.0),\n",
       " ('2012-10-27 02', 8, 3, 0.0),\n",
       " ('2012-10-27 03', 8, 0, 0.0),\n",
       " ('2012-10-27 04', 0, 6, 0.0),\n",
       " ('2012-10-27 05', 2, 6, 0.0),\n",
       " ('2012-10-27 06', 3, 6, 0.0),\n",
       " ('2012-10-27 07', 6, 5, 0.0),\n",
       " ('2012-10-27 08', 3, 5, 0.0),\n",
       " ('2012-10-27 09', 9, 6, 0.0),\n",
       " ('2012-10-27 10', 14, 7, 0.0),\n",
       " ('2012-10-27 11', 20, 5, 0.0),\n",
       " ('2012-10-27 12', 6, 8, 0.0),\n",
       " ('2012-10-27 13', 9, 8, 0.0),\n",
       " ('2012-10-27 14', 6, 10, 0.0),\n",
       " ('2012-10-27 15', 7, 10, 0.0),\n",
       " ('2012-10-27 16', 10, 7, 0.0),\n",
       " ('2012-10-27 17', 14, 7, 0.0),\n",
       " ('2012-10-27 18', 12, 7, 0.0),\n",
       " ('2012-10-27 19', 36, 8, 0.0),\n",
       " ('2012-10-27 20', 16, 7, 0.0),\n",
       " ('2012-10-27 21', 17, 9, 0.0),\n",
       " ('2012-10-27 22', 13, 9, 0.0),\n",
       " ('2012-10-27 23', 30, 8, 0.0),\n",
       " ('2012-10-28 00', 8, 11, 0.0),\n",
       " ('2012-10-28 01', 16, 8, 0.0),\n",
       " ('2012-10-28 02', 4, 8, 0.0),\n",
       " ('2012-10-28 03', 8, 9, 0.0),\n",
       " ('2012-10-28 04', 6, 10, 0.0),\n",
       " ('2012-10-28 05', 2, 11, 0.0),\n",
       " ('2012-10-28 06', 0, 10, 0.0),\n",
       " ('2012-10-28 07', 6, 11, 0.0),\n",
       " ('2012-10-28 08', 2, 11, 0.0),\n",
       " ('2012-10-28 09', 7, 11, 0.0),\n",
       " ('2012-10-28 10', 7, 10, 0.0),\n",
       " ('2012-10-28 11', 10, 8, 0.0),\n",
       " ('2012-10-28 12', 6, 7, 0.0),\n",
       " ('2012-10-28 13', 6, 13, 0.0),\n",
       " ('2012-10-28 14', 10, 13, 0.0),\n",
       " ('2012-10-28 15', 9, 13, 0.0),\n",
       " ('2012-10-28 16', 8, 16, 0.0),\n",
       " ('2012-10-28 17', 8, 11, 0.0),\n",
       " ('2012-10-28 18', 7, 15, 0.0),\n",
       " ('2012-10-28 19', 6, 14, 0.0),\n",
       " ('2012-10-28 20', 7, 16, 0.0),\n",
       " ('2012-10-28 21', 5, 14, 0.0),\n",
       " ('2012-10-28 22', 4, 16, 0.0),\n",
       " ('2012-10-28 23', 4, 14, 0.0),\n",
       " ('2012-10-29 00', 3, 16, 0.0),\n",
       " ('2012-10-29 01', 0, 11, 0.0),\n",
       " ('2012-10-29 02', 2, 13, 0.0),\n",
       " ('2012-10-29 03', 0, 17, 0.0),\n",
       " ('2012-10-29 04', 1, 15, 0.0),\n",
       " ('2012-10-29 05', 0, 15, 0.0),\n",
       " ('2012-10-29 06', 0, 16, 0.019999999552965164),\n",
       " ('2012-10-29 07', 3, 17, 0.019999999552965164),\n",
       " ('2012-10-29 09', 2, 16, 0.0),\n",
       " ('2012-10-29 10', 2, 0, 0.0),\n",
       " ('2012-10-29 11', 12, 21, 0.0),\n",
       " ('2012-10-29 12', 30, 15, 0.019999999552965164),\n",
       " ('2012-10-29 13', 6, 24, 0.019999999552965164),\n",
       " ('2012-10-29 14', 20, 23, 0.029999999329447746),\n",
       " ('2012-10-29 15', 6, 26, 0.07000000029802322),\n",
       " ('2012-10-29 16', 9, 23, 0.10000000149011612),\n",
       " ('2012-10-29 17', 4, 29, 0.03999999910593033),\n",
       " ('2012-10-29 18', 6, 21, 0.019999999552965164),\n",
       " ('2012-10-29 19', 0, 25, 0.009999999776482582),\n",
       " ('2012-10-29 21', 1, 15, 0.0),\n",
       " ('2012-10-29 22', 0, 9, 0.019999999552965164),\n",
       " ('2012-10-29 23', 0, 7, 0.029999999329447746),\n",
       " ('2012-10-30 00', 4, 13, 0.029999999329447746),\n",
       " ('2012-10-30 02', 0, 9, 0.029999999329447746),\n",
       " ('2012-10-30 03', 0, 17, 0.03999999910593033),\n",
       " ('2012-10-30 05', 0, 7, 0.009999999776482582),\n",
       " ('2012-10-30 06', 0, 7, 0.009999999776482582),\n",
       " ('2012-10-30 08', 0, 11, 0.009999999776482582),\n",
       " ('2012-10-30 09', 8, 15, 0.009999999776482582),\n",
       " ('2012-10-30 10', 16, 8, 0.019999999552965164),\n",
       " ('2012-10-30 11', 3, 7, 0.0),\n",
       " ('2012-10-30 12', 8, 9, 0.0),\n",
       " ('2012-10-30 13', 12, 7, 0.0),\n",
       " ('2012-10-30 14', 4, 0, 0.0),\n",
       " ('2012-10-30 16', 6, 3, 0.009999999776482582),\n",
       " ('2012-10-30 17', 10, 6, 0.0),\n",
       " ('2012-10-30 18', 8, 5, 0.0),\n",
       " ('2012-10-30 19', 5, 3, 0.0),\n",
       " ('2012-10-30 20', 8, 0, 0.0),\n",
       " ('2012-10-30 21', 6, 5, 0.0),\n",
       " ('2012-10-30 22', 6, 7, 0.0),\n",
       " ('2012-10-30 23', 15, 5, 0.0),\n",
       " ('2012-10-31 01', 1, 5, 0.009999999776482582),\n",
       " ('2012-10-31 03', 1, 8, 0.0),\n",
       " ('2012-10-31 04', 0, 0, 0.0),\n",
       " ('2012-10-31 05', 0, 0, 0.0),\n",
       " ('2012-10-31 06', 2, 6, 0.0),\n",
       " ('2012-10-31 07', 10, 0, 0.0),\n",
       " ('2012-10-31 08', 6, 6, 0.0),\n",
       " ('2012-10-31 09', 10, 6, 0.0),\n",
       " ('2012-10-31 10', 14, 5, 0.0),\n",
       " ('2012-10-31 11', 7, 5, 0.0),\n",
       " ('2012-10-31 12', 6, 9, 0.0),\n",
       " ('2012-10-31 13', 4, 6, 0.0),\n",
       " ('2012-10-31 14', 6, 5, 0.0),\n",
       " ('2012-10-31 15', 5, 3, 0.0),\n",
       " ('2012-10-31 16', 4, 5, 0.0),\n",
       " ('2012-10-31 17', 1, 5, 0.0),\n",
       " ('2012-10-31 18', 6, 3, 0.0),\n",
       " ('2012-10-31 19', 7, 9, 0.0),\n",
       " ('2012-10-31 20', 9, 7, 0.0),\n",
       " ('2012-10-31 21', 3, 7, 0.0),\n",
       " ('2012-10-31 22', 8, 6, 0.0),\n",
       " ('2012-10-31 23', 6, 3, 0.0),\n",
       " ('2012-11-01 00', 4, 3, 0.0),\n",
       " ('2012-11-01 01', 0, 3, 0.0),\n",
       " ('2012-11-01 02', 1, 3, 0.0),\n",
       " ('2012-11-01 03', 6, 0, 0.0),\n",
       " ('2012-11-01 04', 1, 7, 0.0),\n",
       " ('2012-11-01 05', 1, 6, 0.0),\n",
       " ('2012-11-01 06', 1, 13, 0.0),\n",
       " ('2012-11-01 07', 3, 0, 0.0),\n",
       " ('2012-11-01 08', 4, 7, 0.0),\n",
       " ('2012-11-01 09', 5, 3, 0.0),\n",
       " ('2012-11-01 10', 6, 6, 0.0),\n",
       " ('2012-11-01 11', 8, 6, 0.0),\n",
       " ('2012-11-01 12', 7, 11, 0.0),\n",
       " ('2012-11-01 13', 4, 8, 0.0),\n",
       " ('2012-11-01 14', 4, 8, 0.0),\n",
       " ('2012-11-01 15', 8, 0, 0.0),\n",
       " ('2012-11-01 16', 4, 5, 0.0),\n",
       " ('2012-11-01 17', 4, 5, 0.0),\n",
       " ('2012-11-01 18', 9, 9, 0.0),\n",
       " ('2012-11-01 19', 9, 3, 0.0),\n",
       " ('2012-11-01 20', 6, 5, 0.0),\n",
       " ('2012-11-01 21', 6, 8, 0.0),\n",
       " ('2012-11-01 22', 5, 5, 0.0),\n",
       " ('2012-11-01 23', 6, 0, 0.0),\n",
       " ('2012-11-02 00', 4, 5, 0.0),\n",
       " ('2012-11-02 01', 2, 7, 0.0),\n",
       " ('2012-11-02 02', 0, 3, 0.0),\n",
       " ('2012-11-02 03', 1, 3, 0.0),\n",
       " ('2012-11-02 04', 1, 5, 0.0),\n",
       " ('2012-11-02 05', 1, 5, 0.0),\n",
       " ('2012-11-02 06', 4, 6, 0.0),\n",
       " ('2012-11-02 07', 5, 0, 0.0),\n",
       " ('2012-11-02 08', 7, 5, 0.0),\n",
       " ('2012-11-02 09', 4, 7, 0.0),\n",
       " ('2012-11-02 10', 4, 9, 0.0),\n",
       " ('2012-11-02 11', 4, 7, 0.0),\n",
       " ('2012-11-02 12', 11, 7, 0.0),\n",
       " ('2012-11-02 13', 4, 6, 0.0),\n",
       " ('2012-11-02 14', 5, 6, 0.0),\n",
       " ('2012-11-02 15', 5, 5, 0.0),\n",
       " ('2012-11-02 16', 4, 11, 0.0),\n",
       " ('2012-11-02 17', 2, 8, 0.0),\n",
       " ('2012-11-02 18', 1, 9, 0.0),\n",
       " ('2012-11-02 19', 6, 7, 0.0),\n",
       " ('2012-11-02 20', 8, 9, 0.0),\n",
       " ('2012-11-02 21', 12, 7, 0.0),\n",
       " ('2012-11-02 22', 7, 8, 0.0),\n",
       " ('2012-11-02 23', 10, 8, 0.0),\n",
       " ('2012-11-03 00', 8, 7, 0.0),\n",
       " ('2012-11-03 01', 5, 7, 0.0),\n",
       " ('2012-11-03 02', 10, 7, 0.0),\n",
       " ('2012-11-03 03', 3, 7, 0.0),\n",
       " ('2012-11-03 04', 0, 8, 0.0),\n",
       " ('2012-11-03 05', 3, 8, 0.0),\n",
       " ('2012-11-03 06', 1, 7, 0.0),\n",
       " ('2012-11-03 07', 3, 6, 0.0),\n",
       " ('2012-11-03 08', 8, 10, 0.0),\n",
       " ('2012-11-03 09', 6, 13, 0.0),\n",
       " ('2012-11-03 10', 5, 6, 0.0),\n",
       " ('2012-11-03 11', 16, 13, 0.0),\n",
       " ('2012-11-03 12', 10, 13, 0.0),\n",
       " ('2012-11-03 13', 9, 8, 0.0),\n",
       " ('2012-11-03 14', 10, 8, 0.0),\n",
       " ('2012-11-03 15', 5, 7, 0.0),\n",
       " ('2012-11-03 16', 7, 10, 0.0),\n",
       " ('2012-11-03 17', 14, 9, 0.0),\n",
       " ('2012-11-03 18', 12, 9, 0.0),\n",
       " ('2012-11-03 19', 7, 13, 0.0),\n",
       " ('2012-11-03 20', 8, 10, 0.0),\n",
       " ('2012-11-03 21', 13, 9, 0.0),\n",
       " ('2012-11-03 22', 8, 0, 0.0),\n",
       " ('2012-11-03 23', 32, 7, 0.0),\n",
       " ('2012-11-04 00', 8, 9, 0.0),\n",
       " ('2012-11-04 01', 15, 7, 0.0),\n",
       " ('2012-11-04 02', 10, 7, 0.0),\n",
       " ('2012-11-04 03', 3, 7, 0.0),\n",
       " ('2012-11-04 04', 3, 8, 0.0),\n",
       " ('2012-11-04 05', 1, 6, 0.0),\n",
       " ('2012-11-04 06', 1, 6, 0.0),\n",
       " ('2012-11-04 07', 4, 3, 0.0),\n",
       " ('2012-11-04 08', 2, 7, 0.0),\n",
       " ('2012-11-04 09', 8, 9, 0.0),\n",
       " ('2012-11-04 10', 8, 0, 0.0),\n",
       " ('2012-11-04 11', 6, 6, 0.0),\n",
       " ('2012-11-04 12', 21, 8, 0.0),\n",
       " ('2012-11-04 13', 7, 8, 0.0),\n",
       " ('2012-11-04 14', 6, 7, 0.0),\n",
       " ('2012-11-04 15', 4, 7, 0.0),\n",
       " ('2012-11-04 16', 9, 5, 0.0),\n",
       " ('2012-11-04 17', 11, 5, 0.0),\n",
       " ('2012-11-04 18', 9, 0, 0.0),\n",
       " ('2012-11-04 19', 8, 7, 0.0),\n",
       " ('2012-11-04 20', 14, 0, 0.0),\n",
       " ('2012-11-04 21', 6, 7, 0.0),\n",
       " ('2012-11-04 22', 7, 6, 0.0),\n",
       " ('2012-11-04 23', 6, 5, 0.0),\n",
       " ('2012-11-05 00', 6, 0, 0.0),\n",
       " ('2012-11-05 01', 1, 5, 0.0),\n",
       " ('2012-11-05 02', 1, 3, 0.0),\n",
       " ('2012-11-05 03', 0, 7, 0.0),\n",
       " ('2012-11-05 04', 0, 3, 0.0),\n",
       " ('2012-11-05 05', 2, 6, 0.0),\n",
       " ('2012-11-05 06', 5, 8, 0.0),\n",
       " ('2012-11-05 07', 5, 6, 0.0),\n",
       " ('2012-11-05 08', 14, 7, 0.0),\n",
       " ('2012-11-05 09', 11, 3, 0.0),\n",
       " ('2012-11-05 10', 9, 3, 0.0),\n",
       " ('2012-11-05 11', 8, 3, 0.0),\n",
       " ('2012-11-05 12', 9, 5, 0.0),\n",
       " ('2012-11-05 13', 6, 3, 0.0),\n",
       " ('2012-11-05 14', 9, 0, 0.0),\n",
       " ('2012-11-05 15', 3, 8, 0.0),\n",
       " ('2012-11-05 16', 7, 0, 0.0),\n",
       " ('2012-11-05 17', 17, 5, 0.0),\n",
       " ('2012-11-05 18', 16, 5, 0.0),\n",
       " ('2012-11-05 19', 8, 0, 0.0),\n",
       " ('2012-11-05 20', 11, 3, 0.0),\n",
       " ('2012-11-05 21', 10, 7, 0.0),\n",
       " ('2012-11-05 22', 7, 6, 0.0),\n",
       " ('2012-11-05 23', 4, 9, 0.0),\n",
       " ('2012-11-06 00', 4, 6, 0.0),\n",
       " ('2012-11-06 01', 3, 5, 0.0),\n",
       " ('2012-11-06 02', 2, 8, 0.0),\n",
       " ('2012-11-06 03', 2, 10, 0.0),\n",
       " ('2012-11-06 04', 1, 6, 0.0),\n",
       " ('2012-11-06 05', 3, 5, 0.0),\n",
       " ('2012-11-06 06', 3, 7, 0.0),\n",
       " ('2012-11-06 07', 7, 7, 0.0),\n",
       " ('2012-11-06 08', 14, 8, 0.0),\n",
       " ('2012-11-06 09', 7, 3, 0.0),\n",
       " ('2012-11-06 10', 11, 6, 0.0),\n",
       " ('2012-11-06 11', 2, 7, 0.0),\n",
       " ('2012-11-06 12', 8, 5, 0.0),\n",
       " ('2012-11-06 13', 15, 0, 0.0),\n",
       " ('2012-11-06 14', 12, 6, 0.0),\n",
       " ('2012-11-06 15', 8, 6, 0.0),\n",
       " ('2012-11-06 16', 7, 5, 0.0),\n",
       " ('2012-11-06 17', 9, 5, 0.0),\n",
       " ('2012-11-06 18', 9, 3, 0.0),\n",
       " ('2012-11-06 19', 13, 3, 0.0),\n",
       " ('2012-11-06 20', 8, 7, 0.0),\n",
       " ('2012-11-06 21', 9, 7, 0.0),\n",
       " ('2012-11-06 22', 11, 7, 0.0),\n",
       " ('2012-11-06 23', 22, 3, 0.0)]"
      ]
     },
     "execution_count": 407,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine.execute(QUERY_6).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2012aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query_to_file(QUERY_6, \"trips_precipitation_windspeed.sql\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b891c4",
   "metadata": {},
   "source": [
    "## Part 4: Visualizing the Data\n",
    "\n",
    "_A checklist of requirements to keep you on track. Remove this whole cell before submitting the project. The order of these tasks aren't necessarily the order in which they need to be done. It's okay to do them in an order that makes sense to you._\n",
    "\n",
    "* [ ] Create an appropriate visualization for the first query/question in part 3\n",
    "* [ ] Create a visualization that shows the average distance traveled per month (regardless of year - so group by each month). Include the 90% confidence interval around the mean in the visualization\n",
    "* [ ] Define three lat/long coordinate boxes around the three major New York airports: LGA, JFK, and EWR (you can use bboxfinder to help). Create a visualization that compares what day of the week was most popular for drop offs for each airport.\n",
    "* [ ] Create a heatmap of all hired trips over a map of the area. Consider using KeplerGL or another library that helps generate geospatial visualizations.\n",
    "* [ ] Create a scatter plot that compares tip amount versus distance.\n",
    "* [ ] Create another scatter plot that compares tip amount versus precipitation amount.\n",
    "\n",
    "_Be sure these cells are executed so that the visualizations are rendered when the notebook is submitted._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbc473a",
   "metadata": {},
   "source": [
    "### Visualization 1\n",
    "\n",
    "_**TODO:** Create an appropriate visualization for the most popular hour of the day to take a yellow taxi from 01-2009 to 06-2015._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f5b151b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def popular_hours(dataframe):\n",
    "    plot_title = \"Total Number of Taxi Trips(Hours)\"\n",
    "    x_label = \"Hours\"\n",
    "    y_label = \"Total Number of Taxi Trips\"\n",
    "    dataframe.plot(kind=\"bar\",x=\"hours\", y=\"hour_frequency\", title=plot_title, xlabel=x_label, ylabel=y_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "eb2c4748",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_1():\n",
    "    # Query SQL database for the data needed.\n",
    "    # You can put the data queried into a pandas dataframe, if you wish\n",
    "    dataframe = pd.read_sql_query(QUERY_1, engine)\n",
    "    df = dataframe.sort_values(by = \"hours\", ascending = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4bffdef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "some_dataframe = get_data_for_visual_1()\n",
    "popular_hours(some_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b90b107b",
   "metadata": {},
   "source": [
    "### Visualization 2\n",
    "\n",
    "_**TODO 1:** Create a visualization that shows the average distance traveled per month (regardless of year - so group by each month)._\n",
    "\n",
    "_**TODO 2:** Include the 90% confidence interval around the mean in the visualization._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "97b82e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_per_month(dataframe):\n",
    "    plot_title = \"Average Distance Travelled(Month)\"\n",
    "    x_label = \"Month\"\n",
    "    y_label = \"Average Distance\"\n",
    "    dataframe.plot(kind=\"bar\",x=\"month\", y=\"average_distance\", title=plot_title, xlabel=x_label, ylabel=y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "053cd95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_2():\n",
    "    # Query SQL database for the data needed.\n",
    "    QUERY_avg = \"\"\"\n",
    "    WITH hired_trips AS\n",
    "    (\n",
    "    SELECT pickup_datetime, distance FROM taxi_trips\n",
    "    UNION\n",
    "    SELECT pickup_datetime, distance FROM uber_trips\n",
    "    )\n",
    "    \n",
    "    SELECT strftime(\"%m\", pickup_datetime) AS month,\n",
    "    AVG(distance_by_month) AS average_distance\n",
    "    \n",
    "    FROM (\n",
    "    SELECT strftime(\"%Y-%m\",pickup_datetime) AS Yr_Month,\n",
    "    SUM(distance) AS distance_by_month\n",
    "    FROM hired_trips\n",
    "    GROUP BY Yr_Month)\n",
    "    \n",
    "    GROUP BY Month\n",
    "    \n",
    "    \"\"\"\n",
    "    dataframe = pd.read_sql_query(QUERY_avg, engine)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "471e6f97",
   "metadata": {},
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(sqlite3.OperationalError) no such column: pickup_datetime\n[SQL: \n    WITH hired_trips AS\n    (\n    SELECT pickup_datetime, distance FROM taxi_trips\n    UNION\n    SELECT pickup_datetime, distance FROM uber_trips\n    )\n    \n    SELECT strftime(\"%m\", pickup_datetime) AS month,\n    AVG(distance_by_month) AS average_distance\n    \n    FROM (\n    SELECT strftime(\"%Y-%m\",pickup_datetime) AS Yr_Month,\n    SUM(distance) AS distance_by_month\n    FROM hired_trips\n    GROUP BY Yr_Month)\n    \n    GROUP BY Month\n    \n    ]\n(Background on this error at: http://sqlalche.me/e/13/e3q8)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[1;32m   1266\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt_handled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m                     self.dialect.do_execute_no_params(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                         \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sqlalchemy/engine/default.py\u001b[0m in \u001b[0;36mdo_execute_no_params\u001b[0;34m(self, cursor, statement, context)\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute_no_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m         \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: no such column: pickup_datetime",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mOperationalError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-081f62feb669>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msome_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_data_for_visual_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdistance_per_month\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msome_dataframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-77-1d3f4f694d5b>\u001b[0m in \u001b[0;36mget_data_for_visual_2\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \"\"\"\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mdataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mQUERY_avg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_sql_query\u001b[0;34m(sql, con, index_col, coerce_float, params, parse_dates, chunksize)\u001b[0m\n\u001b[1;32m    375\u001b[0m     \"\"\"\n\u001b[1;32m    376\u001b[0m     \u001b[0mpandas_sql\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpandasSQL_builder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m     return pandas_sql.read_query(\n\u001b[0m\u001b[1;32m    378\u001b[0m         \u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \u001b[0mindex_col\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_col\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mread_query\u001b[0;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize)\u001b[0m\n\u001b[1;32m   1293\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/io/sql.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1159\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1160\u001b[0m         \u001b[0;34m\"\"\"Simple passthrough to SQLAlchemy connectable\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m         return self.connectable.execution_options(no_parameters=True).execute(\n\u001b[0m\u001b[1;32m   1162\u001b[0m             \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m         )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[1;32m   2236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2237\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_contextual_connect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclose_with_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2238\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2240\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, object_, *multiparams, **params)\u001b[0m\n\u001b[1;32m   1004\u001b[0m         \"\"\"\n\u001b[1;32m   1005\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1006\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1007\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1008\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mobject_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_on_connection\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_text\u001b[0;34m(self, statement, multiparams, params)\u001b[0m\n\u001b[1;32m   1173\u001b[0m         \u001b[0mdialect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdialect\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m         \u001b[0mparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_distill_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m         ret = self._execute_context(\n\u001b[0m\u001b[1;32m   1176\u001b[0m             \u001b[0mdialect\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m             \u001b[0mdialect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecution_ctx_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_statement\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1316\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mBaseException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1317\u001b[0;31m             self._handle_dbapi_exception(\n\u001b[0m\u001b[1;32m   1318\u001b[0m                 \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1319\u001b[0m             )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_handle_dbapi_exception\u001b[0;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[1;32m   1509\u001b[0m                 \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewraise\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_traceback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1510\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mshould_wrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1511\u001b[0;31m                 util.raise_(\n\u001b[0m\u001b[1;32m   1512\u001b[0m                     \u001b[0msqlalchemy_exception\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwith_traceback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1513\u001b[0m                 )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sqlalchemy/util/compat.py\u001b[0m in \u001b[0;36mraise_\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;31m# credit to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sqlalchemy/engine/base.py\u001b[0m in \u001b[0;36m_execute_context\u001b[0;34m(self, dialect, constructor, statement, parameters, *args)\u001b[0m\n\u001b[1;32m   1265\u001b[0m                             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mevt_handled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m                     self.dialect.do_execute_no_params(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                         \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m                     )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/sqlalchemy/engine/default.py\u001b[0m in \u001b[0;36mdo_execute_no_params\u001b[0;34m(self, cursor, statement, context)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdo_execute_no_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatement\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 596\u001b[0;31m         \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mis_disconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOperationalError\u001b[0m: (sqlite3.OperationalError) no such column: pickup_datetime\n[SQL: \n    WITH hired_trips AS\n    (\n    SELECT pickup_datetime, distance FROM taxi_trips\n    UNION\n    SELECT pickup_datetime, distance FROM uber_trips\n    )\n    \n    SELECT strftime(\"%m\", pickup_datetime) AS month,\n    AVG(distance_by_month) AS average_distance\n    \n    FROM (\n    SELECT strftime(\"%Y-%m\",pickup_datetime) AS Yr_Month,\n    SUM(distance) AS distance_by_month\n    FROM hired_trips\n    GROUP BY Yr_Month)\n    \n    GROUP BY Month\n    \n    ]\n(Background on this error at: http://sqlalche.me/e/13/e3q8)"
     ]
    }
   ],
   "source": [
    "some_dataframe = get_data_for_visual_2()\n",
    "distance_per_month(some_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0d5bc5",
   "metadata": {},
   "source": [
    "### Visualization 3\n",
    "\n",
    "_**TODO:** Define three lat/long coordinate boxes around the three major New York airports: LGA, JFK, and EWR (you can use bboxfinder to help)._\n",
    "\n",
    "_**TODO:** Create a visualization that compares what day of the week was most popular for drop offs for each airport.._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4416619d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e310ebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e549f13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f213bb3",
   "metadata": {},
   "source": [
    "### Visualization 4\n",
    "\n",
    "_**TODO:** Create a heatmap of all hired trips over a map of the area. Consider using KeplerGL or another library that helps generate geospatial visualizations.._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9802939a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e97f251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e393730",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a79b3fd1",
   "metadata": {},
   "source": [
    "### Visualization 5\n",
    "\n",
    "_**TODO:** Create a scatter plot that compares tip amount versus distance.._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47095669",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tip_vs_distance(dataframe):\n",
    "    plot_title = \"Tip Amount Versus Distance\"\n",
    "    x_label = \"Distance\"\n",
    "    y_label = \"Tip Amount\"\n",
    "    dataframe[(dataframe[\"distance\"]>=0) & (dataframe[\"tip_amount\"]>=0)].plot(kind=\"scatter\",x=\"distance\", y=\"tip_amount\", title=plot_title, xlabel=x_label, ylabel=y_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6f691f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_5():\n",
    "    QUERY_tip_distance = \"\"\"\n",
    "    SELECT tip_amount, distance\n",
    "    FROM taxi_trips\n",
    "    \"\"\"\n",
    "    dataframe = pd.read_sql_query(QUERY_tip_distance, engine)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "252bf51d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m some_dataframe \u001b[38;5;241m=\u001b[39m \u001b[43mget_data_for_visual_5\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m tip_vs_distance(some_dataframe)\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36mget_data_for_visual_5\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_data_for_visual_5\u001b[39m():\n\u001b[1;32m      2\u001b[0m     QUERY_tip_distance \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124m    SELECT tip_amount, distance\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124m    FROM taxi_trips\u001b[39m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m----> 6\u001b[0m     dataframe \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_sql_query(QUERY_tip_distance, engine)\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataframe\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "some_dataframe = get_data_for_visual_5()\n",
    "tip_vs_distance(some_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e096f36e",
   "metadata": {},
   "source": [
    "### Visualization 6\n",
    "\n",
    "_**TODO:** Create a scatter plot that compares tip amount versus precipitation.._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f42be3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tip_vs_precipitation(dataframe):\n",
    "    plot_title = \"Tip Amount Versus Precipitation\"\n",
    "    x_label = \"Daily Precipication\"\n",
    "    y_label = \"Tip Amount\"\n",
    "    dataframe[(dataframe[\"DailyPrecipitation\"]>=0) & (dataframe[\"tip_amount\"]>=0)].sample(200).plot(kind=\"scatter\",x=\"DailyPrecipitation\", y=\"tip_amount\", title=plot_title, xlabel=x_label, ylabel=y_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f241503",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_for_visual_6():\n",
    "    QUERY_tip_precipitation = \"\"\"\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "    dataframe = pd.read_sql_query(QUERY_tip_precipitation, engine)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6391cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "some_dataframe = get_data_for_visual_6()\n",
    "tip_vs_distance(some_dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b435e2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d85504f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
